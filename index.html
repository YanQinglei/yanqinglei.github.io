<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>BulingQAQ的个人博客</title><meta name="author" content="BulingQAQ"><meta name="copyright" content="BulingQAQ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="不知归路，宁愿一世无悔追逐">
<meta property="og:type" content="website">
<meta property="og:title" content="BulingQAQ的个人博客">
<meta property="og:url" content="https://yanqinglei.github.io/">
<meta property="og:site_name" content="BulingQAQ的个人博客">
<meta property="og:description" content="不知归路，宁愿一世无悔追逐">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yanqinglei.github.io/img/spy_family_avatar.jpg">
<meta property="article:author" content="BulingQAQ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yanqinglei.github.io/img/spy_family_avatar.jpg"><link rel="shortcut icon" href="/img/icon.png"><link rel="canonical" href="https://yanqinglei.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'BulingQAQ的个人博客',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-03-03 15:46:49'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/spy_family_avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/life/"><i class="fa-fw fa fa-camera"></i><span> 生活</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/index_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="BulingQAQ的个人博客"><span class="site-name">BulingQAQ的个人博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/life/"><i class="fa-fw fa fa-camera"></i><span> 生活</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">BulingQAQ的个人博客</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/YanQinglei" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/OctYZ" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1819615836&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1819615836@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/image-synthesis-review-dlaf/" title="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202503021507800.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review"></a></div><div class="recent-post-info"><a class="article-title" href="/image-synthesis-review-dlaf/" title="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review">【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-03T07:43:01.091Z" title="发表于 2025-03-03 15:43:01">2025-03-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/VAE/">VAE</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DM/">DM</a></span></div><div class="content">0. Abstract

背景：
医学图像数据获取成本高且受隐私法规约束，越来越多的研究提出使用深度生成模型来生成更符合数据真实分布的、逼真且多样化的数据。
工作：

概述了变分自编码器、生成对抗网络和扩散模型的最新技术进展；
讨论了它们在医学成像中不同下游任务中的潜在应用，包括分类、分割和跨模态转换；
评估了每种模型的优势和局限性；
提出了未来研究的建议方向。

目标：
我们的目标是全面综述深度生成模型在医学图像增强中的应用，并强调这些模型在提高医学图像分析中深度学习算法性能方面的潜力。
1. Introduction


生成对抗网络（GANs）已展示了生成逼真图像的能力，因此该架构在医学领域被广泛应用，并被纳入多项数据增强综述。然而，GANs也存在一些缺点，如学习不稳定、难以收敛以及模式崩溃，即生成器仅生成少量样本的状态。
变分自编码器（VAEs）是另一种深度生成模型，在数据增强中受到的关注较少。VAEs在输出多样性方面优于GANs，且不会出现模式崩溃，但其主要问题是生成的图像往往模糊不清，这是由于损失函数中的正则化项导致的。
扩散模型（DMs）展现出生成逼真且多样化输出的强大能 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-sdat/" title="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202503011627746.png)" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-sdat/" title="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis">【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-02T02:21:15.559Z" title="发表于 2025-03-02 10:21:15">2025-03-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Sim2Real/">Sim2Real</a></span></div><div class="content">Abstract

背景：
AI在介入性图像分析中的潜在应用仍未被充分挖掘。在实时手术过程中收集的数据进行事后分析存在根本性和实践性的限制，包括伦理考虑、成本、可扩展性、数据完整性以及缺乏真实基准。
工作：
1、展示了一种从人体模型中创建逼真模拟图像的可行方案，作为大规模原位数据收集的替代和补充。
2、 创建X射线图像分析模型迁移范式——称为SyntheX。
贡献：
1、 证明通过在现实合成的数据上训练AI图像分析模型，并结合当代领域泛化技术，能够在真实数据上获得与精确匹配的真实数据训练集相当的表现。
2、 SyntheX甚至能够超越基于真实数据训练的模型，显著加速基于X射线的智能系统的构思、设计和评估提供了机会。

真实数据与仿真数据之间的特性差异通常被称为“领域差距”
AI模型在来自不同领域的数据上表现的能力，即与其训练数据存在领域差距的情况，被称为“领域泛化”。
迄今为止尚无研究使用精确匹配的跨领域数据集来孤立领域泛化的影响。


SyntheX框架，该框架旨在开发基于合成数据的通用人工智能算法，用于X射线图像分析，这些合成数据完全由标注的计算机断层扫描（CT）模拟生成。通过从C ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/image-synthesis-review-03/" title="【论文阅读】Generating Synthetic Data for Medical Imaging"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202412031045821.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Generating Synthetic Data for Medical Imaging"></a></div><div class="recent-post-info"><a class="article-title" href="/image-synthesis-review-03/" title="【论文阅读】Generating Synthetic Data for Medical Imaging">【论文阅读】Generating Synthetic Data for Medical Imaging</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-12-03T03:25:53.000Z" title="发表于 2024-12-03 11:25:53">2024-12-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/">扩散模型</a></span></div><div class="content">Abstract

背景：
医学成像任务，如分类或分割，需要大量不同的图像数据集。
挑战：
合成图像的真实性和多样性，同时保持数据的不可识别性，评估基于合成数据训练的模型的性能和通用性，以及高计算成本。
贡献：
本文综述了当前医学影像学中合成数据的研究现状，并重点介绍了该领域当前面临的主要挑战，以指导今后的研究和发展。
0

在合成医学成像中，生成模型已用于生成脑部MRI扫描（16）、视网膜图像（17）和数字病理图像中的乳腺癌组织（18）。
合成数据有更多潜在的应用，例如在相同或不同模式之间转换图像、生成合成对比度增强图像、AI解释性（即使AI对人类可理解）和放射科医师培训。
本综述旨在为放射科医生和影像学研究人员提供一个关于合成数据的综合参考，作为确定该领域关键挑战和指导未来工作的路线图。

（由扩散模型生成并由放射科医师标记的合成胸片。随机抽取50张生成图像和50张真实胸片，由具有10年以上心胸成像临床经验的委员会认证放射科医师独立标记为合成或真实。最上面一行显示了被放射科医生误认为真实的合成胸片。下面一行显示了正确识别为合成的合成胸片。两行图像都是通过扩散模型生成的，扩散模型是根 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-vgg19/" title="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409301638643.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-vgg19/" title="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合">【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-10T13:52:22.000Z" title="发表于 2024-10-10 21:52:22">2024-10-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/">图像融合</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/VGG/">VGG</a></span></div><div class="content">3. 基于协同学习机制的 CNN 肺肿瘤图像融合

3.1 网络架构


三部分：

两个独立的编码器
协同学习与融合模块
图像重建部分

3.1.1 特定模态编码器

编码器：
（卷积层×2+最大池化层）×3
每一 次卷积后都进行以 0 为均值，单位方差分布的归一化。
归一化之后再使用 LeakyReLU 函数进行激活。
卷积层输出：
F=LeakyReLU(W∗X+b)F = LeakyReLU(W*X+b)
F=LeakyReLU(W∗X+b)

3.1.2 协同学习CNN激活函数

ReLU
LeakyReLU
3.1.3 协同学习CNN损失函数

交叉熵损失函数
e=−[ylog(p)+(1−y)log(1−p)]e = -[ylog(p)+(1-y)log(1-p)]
e=−[ylog(p)+(1−y)log(1−p)]
3.1.4 多模态特征协同学习和融合模块

（1）协同学习
两部分：
协同学习单元
融合操作
FCT:w∗h∗cF_{CT}: w*h*cFCT​:w∗h∗c
FPET:w∗h∗cF_{PET}: w*h*cFPET​:w∗h∗c
穿插堆叠：Xmulti: ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/trans-aiay/" title="【论文阅读】Attention is All you Need"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202410041958010.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Attention is All you Need"></a></div><div class="recent-post-info"><a class="article-title" href="/trans-aiay/" title="【论文阅读】Attention is All you Need">【论文阅读】Attention is All you Need</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-10-06T08:38:17.000Z" title="发表于 2024-10-06 16:38:17">2024-10-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Transformer/">Transformer</a></span></div><div class="content">Abstract

贡献：
提出了Transformer，完全基于注意力机制，摒弃了循环和卷积网络。
结果：
本模型在质量上优于现有模型，同时具有更高的并行性，并且显著减少了训练时间。
1. Introduction


long short-term memory（LSTM）——长短期记忆网络
gated recurrent neural networks——门控循环神经网络

循环模型通常沿着输入和输出序列的符号位置来分解计算。通过将位置与计算时间步骤对齐，它们生成一系列隐藏状态 ht，作为前一个隐藏状态 ht−1 和位置 t 的输入的函数。
Transformer完全摒弃循环网络、完全依赖注意力机制来捕捉输入和输出之间全局依赖关系的模型架构。
显著允许增加并行化。
2. Background

减少序列计算。

Extended Neural GPU
ByteNet
ConvS2S
在这些模型中，关联任意两个输入或输出位置信号所需的操作次数随着位置之间的距离而增加。

Self-attention，是一种通过关联同一序列中不同位置来计算该序列表示的注意力机制。
End-to-en ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-pccm/" title="【论文阅读】PET/CT Cross-modal medical image fusion of lung tumors based on DCIF-GAN"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409291040191.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】PET/CT Cross-modal medical image fusion of lung tumors based on DCIF-GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-pccm/" title="【论文阅读】PET/CT Cross-modal medical image fusion of lung tumors based on DCIF-GAN">【论文阅读】PET/CT Cross-modal medical image fusion of lung tumors based on DCIF-GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-29T14:02:52.000Z" title="发表于 2024-09-29 22:02:52">2024-09-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/">图像融合</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DCIF-GAN/">DCIF-GAN</a></span></div><div class="content">摘要

背景：
基于GAN的融合方法存在训练不稳定，提取图像的局部和全局上下文语义信息能力不足，交互融合程度不够等问题
贡献：
提出双耦合交互式融合GAN（Dual-Coupled Interactive Fusion GAN，DCIF-GAN）：

设计了双生成器双鉴别器GAN，通过权值共享机制实现生成器之间和鉴别器之间的耦合，通过全局自注意力机制实现交互式融合；
设计耦合CNN-Transformer的特征提取模块（Coupled CNN-T ransformer Feature Extraction Module, CC-TFEM）和特征重构模块（CNN-T ransformer F eature Reconstruction Module, C-TFRM），提升了对同一模态图像内部的局部和全局特征信息提取能力；
设计跨模态交互式融合模块（Cross Model Intermodal Fusion Module, CMIFM），通过跨模态自注意力机制，进一步整合不同模态间的全局交互信息。

结果：
在肺部肿瘤PET/CT医学图像数据集上进行实验，模型能够突出病变区域信息，融合图像 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/image-fusion-review-01/" title="【论文阅读】多模态医学图像融合方法的研究进展"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409291905818.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】多模态医学图像融合方法的研究进展"></a></div><div class="recent-post-info"><a class="article-title" href="/image-fusion-review-01/" title="【论文阅读】多模态医学图像融合方法的研究进展">【论文阅读】多模态医学图像融合方法的研究进展</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-29T11:00:32.000Z" title="发表于 2024-09-29 19:00:32">2024-09-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/">图像融合</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span></div><div class="content">摘要

背景：
多模态融合技术可将多模态的医学图像融合到单模态的图像中，且单模态图像具有多种模态图像间的互补信息， 从而在单一图像中得到充足的便于临床诊断的信息。
贡献：
本文将多模态医学图像融合方法整理为两种，分别为传统融合方法和基于深度学习的融合方法。
0. 引言

图像融合是图像处理的子领域。
多模态医学图像：MRI、CT、PET、SPECT、US。
1. 传统融合方法

多尺度变换（MST）、稀疏表示（SR）、基于子空间、基于显著特征、混合模型
MST：
基于MST的方法包括多尺度分解、多尺度融合和多尺度重建等步骤。

具有多个特征的联合拉普拉斯金字塔方法
使用高斯滤波技术提高图像质量，然后使用离散小波变换增强融合图像的效果
从一组结合一系列稀疏系数的训练图像中学习到的过完整字典中生成融合图像
将已配准的医学图像按照块的几何方向划分为分类块
使用稀疏表示和邻域能量活动算子将源图像分为基础层和细节层
具有组稀疏性和图正则化的字典学习（DL-GSGR）

基于子空间：
主要包括主成分分析（PCA）、独立成分分析（ICA）和非负矩阵分解（NMF）。

将强度-色调-饱和度变换和主成分 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-wgan/" title="【论文阅读】Wasserstein GAN"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409291311952.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Wasserstein GAN"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-wgan/" title="【论文阅读】Wasserstein GAN">【论文阅读】Wasserstein GAN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-29T06:26:18.000Z" title="发表于 2024-09-29 14:26:18">2024-09-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/WGAN/">WGAN</a></span></div><div class="content">贡献：

彻底解决GAN训练不稳定的问题，不再需要小心平衡生成器和判别器的训练程度
基本解决了collapse mode的问题，确保了生成样本的多样性
训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高 
以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到

改进：

判别器最后一层去掉sigmoid
生成器和判别器的loss不取log
每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c
不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行

1. 原始GAN的问题

1.1 判别器越好，生成器梯度消失越严重

原始GAN训练有一个trick，就是别把判别器训练得太好，否则在实验中生成器会完全学不动（loss降不下去）。
根据原始GAN定义的判别器loss，可以得到最优判别器的形式；而在最优判别器的下，可以把原始GAN定义的生成器loss等价变换为最小化真实分布Pr与生成分布Pg之间的JS散度。
越训练判别器，它就越接近最优，最小化生成器的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409202307724.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】MedGAN:Medical image translation using GANs"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs">【论文阅读】MedGAN:Medical image translation using GANs</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-21T14:04:30.000Z" title="发表于 2024-09-21 22:04:30">2024-09-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/MedGAN/">MedGAN</a></span></div><div class="content">Abstract

背景：
图像到图像的转换被认为是医学图像分析领域的一个新的前沿领域。
工作：
提出了一种新的医学图像到图像的转换框架MedGAN：
将对抗性框架与非对抗性损失的新组合相结合；
生成器——CasNet，该结构通过编码器-解码器对的逐步细化来增强翻译后的医学输出的清晰度；
判别器——作为一个可训练的特征提取惩罚之间的差异转换医学图像和期望的模式；
利用风格传递损失将目标图像的纹理和精细结构匹配到转换后的图像；
应用于三个不同的任务：PETCT翻译、MR运动伪影校正和PET图像去噪。
结果：
MedGAN优于其他现有的转换方法。
1. Introduction

由于可能引入不切实际的信息，将输入图像模态转换为输出模态的任务具有挑战性。这显然会使合成图像不可靠，无法用于诊断目的。
1.1 Classical approaches

1.2 Generative models

1.3 Medical image translation

1.4 Contributions

MedGAN的主要目的不是诊断，而是进一步增强需要全局一致图像属性的技术后处理任务。

MedGA ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409191616851.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks">【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-19T09:19:12.000Z" title="发表于 2024-09-19 17:19:12">2024-09-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DCGAN/">DCGAN</a></span></div><div class="content">Abstract

背景：
希望能缩小CNN在监督学习和无监督学习之间成功应用的差距。
贡献：
引入了一类称为深度卷积生成对抗网络（DCGAN）的CNN。
结果：
DCGAN 在生成器和判别器中都能从对象到场景学习表示层次结构。
1. Introduction

贡献：

提出DCGAN
用于图像分类任务，展示其性能
对滤波器进行了可视化，证明特定滤波器已经学会了绘制特定对象
生成器具有向量算术特性，允许轻松操作生成样本的许多语义特征

2. Related Work

2.1 Representation Learning From Unlabeled Data——基于未标记数据的表示学习


聚类
自动编码器

2.2 Generating Natural Images——生成自然图像

生成图像模型分为两类：参数和非参数。
2.3 Visualizing The Internals Of CNNs——CNN内部可视化

使用输入上的梯度下降，可以检查激活某些滤波器子集的理想图像。
3. Approach And Model Architecture


DCGAN的架构：

用带 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/spy_family_avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">BulingQAQ</div><div class="author-info__description">不知归路，宁愿一世无悔追逐</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/YanQinglei"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/YanQinglei" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/OctYZ" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1819615836&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1819615836@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">请多多指教</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/image-synthesis-review-dlaf/" title="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202503021507800.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review"/></a><div class="content"><a class="title" href="/image-synthesis-review-dlaf/" title="【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review">【论文阅读】Deep Learning Approaches for Data Augmentation in Medical Imaging：A Review</a><time datetime="2025-03-03T07:43:01.091Z" title="发表于 2025-03-03 15:43:01">2025-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-sdat/" title="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202503011627746.png)" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis"/></a><div class="content"><a class="title" href="/gan-sdat/" title="【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis">【论文阅读】Synthetic data accelerates the development of generalizable learning-based algorithms for X-ray image analysis</a><time datetime="2025-03-02T02:21:15.559Z" title="发表于 2025-03-02 10:21:15">2025-03-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/image-synthesis-review-03/" title="【论文阅读】Generating Synthetic Data for Medical Imaging"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202412031045821.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Generating Synthetic Data for Medical Imaging"/></a><div class="content"><a class="title" href="/image-synthesis-review-03/" title="【论文阅读】Generating Synthetic Data for Medical Imaging">【论文阅读】Generating Synthetic Data for Medical Imaging</a><time datetime="2024-12-03T03:25:53.000Z" title="发表于 2024-12-03 11:25:53">2024-12-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-vgg19/" title="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409301638643.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合"/></a><div class="content"><a class="title" href="/gan-vgg19/" title="【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合">【论文阅读】基于深度学习的肺肿瘤PET-CT图像融合</a><time datetime="2024-10-10T13:52:22.000Z" title="发表于 2024-10-10 21:52:22">2024-10-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/trans-aiay/" title="【论文阅读】Attention is All you Need"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202410041958010.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Attention is All you Need"/></a><div class="content"><a class="title" href="/trans-aiay/" title="【论文阅读】Attention is All you Need">【论文阅读】Attention is All you Need</a><time datetime="2024-10-06T08:38:17.000Z" title="发表于 2024-10-06 16:38:17">2024-10-06</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="card-category-list-name">论文阅读</span><span class="card-category-list-count">18</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%88%86%E5%89%B2/"><span class="card-category-list-name">分割</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"><span class="card-category-list-name">图像生成</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/"><span class="card-category-list-name">图像融合</span><span class="card-category-list-count">3</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" style="font-size: 1.1em; color: #999">扩散模型</a> <a href="/tags/BoneMetastasis/" style="font-size: 1.1em; color: #999">BoneMetastasis</a> <a href="/tags/WGAN/" style="font-size: 1.1em; color: #999">WGAN</a> <a href="/tags/SPECT/" style="font-size: 1.1em; color: #999">SPECT</a> <a href="/tags/DM/" style="font-size: 1.1em; color: #999">DM</a> <a href="/tags/CycleGAN/" style="font-size: 1.1em; color: #999">CycleGAN</a> <a href="/tags/DCGAN/" style="font-size: 1.1em; color: #999">DCGAN</a> <a href="/tags/Transformer/" style="font-size: 1.1em; color: #999">Transformer</a> <a href="/tags/DCIF-GAN/" style="font-size: 1.1em; color: #999">DCIF-GAN</a> <a href="/tags/Sim2Real/" style="font-size: 1.1em; color: #999">Sim2Real</a> <a href="/tags/CNN/" style="font-size: 1.1em; color: #999">CNN</a> <a href="/tags/VAE/" style="font-size: 1.1em; color: #999">VAE</a> <a href="/tags/GAN/" style="font-size: 1.5em; color: #99a9bf">GAN</a> <a href="/tags/VGG/" style="font-size: 1.1em; color: #999">VGG</a> <a href="/tags/MedGAN/" style="font-size: 1.1em; color: #999">MedGAN</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/03/"><span class="card-archive-list-date">三月 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">19</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">55.8k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-03-03T07:46:49.604Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409021053834.png')"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By BulingQAQ</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生","虽千万人吾往矣","长风破浪会有时，直挂云帆济沧海","三军可夺帅也，匹夫不可夺志也","俱往矣，数风流人物，还看今朝","问汝平生功业，黄州惠州儋州"])
  } else {
    document.getElementById("subtitle").textContent = "竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生"
  }
}
typedJSFn.run(subtitleType)</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>