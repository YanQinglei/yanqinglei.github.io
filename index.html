<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>BulingQAQ的个人博客</title><meta name="author" content="BulingQAQ"><meta name="copyright" content="BulingQAQ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="不知归路，宁愿一世无悔追逐">
<meta property="og:type" content="website">
<meta property="og:title" content="BulingQAQ的个人博客">
<meta property="og:url" content="https://yanqinglei.github.io/">
<meta property="og:site_name" content="BulingQAQ的个人博客">
<meta property="og:description" content="不知归路，宁愿一世无悔追逐">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yanqinglei.github.io/img/spy_family_avatar.jpg">
<meta property="article:author" content="BulingQAQ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yanqinglei.github.io/img/spy_family_avatar.jpg"><link rel="shortcut icon" href="/img/icon.png"><link rel="canonical" href="https://yanqinglei.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'BulingQAQ的个人博客',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-09-21 22:27:44'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/spy_family_avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/life/"><i class="fa-fw fa fa-camera"></i><span> 生活</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/index_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="BulingQAQ的个人博客"><span class="site-name">BulingQAQ的个人博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/life/"><i class="fa-fw fa fa-camera"></i><span> 生活</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">BulingQAQ的个人博客</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/YanQinglei" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/OctYZ" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1819615836&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1819615836@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409202307724.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】MedGAN:Medical image translation using GANs"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs">【论文阅读】MedGAN:Medical image translation using GANs</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-21T14:04:30.000Z" title="发表于 2024-09-21 22:04:30">2024-09-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/MedGAN/">MedGAN</a></span></div><div class="content">Abstract
背景：图像到图像的转换被认为是医学图像分析领域的一个新的前沿领域。
工作：提出了一种新的医学图像到图像的转换框架MedGAN：将对抗性框架与非对抗性损失的新组合相结合；生成器——CasNet，该结构通过编码器-解码器对的逐步细化来增强翻译后的医学输出的清晰度；判别器——作为一个可训练的特征提取惩罚之间的差异转换医学图像和期望的模式；利用风格传递损失将目标图像的纹理和精细结构匹配到转换后的图像；应用于三个不同的任务：PETCT翻译、MR运动伪影校正和PET图像去噪。
结果：MedGAN优于其他现有的转换方法。
1. Introduction
由于可能引入不切实际的信息，将输入图像模态转换为输出模态的任务具有挑战性。这显然会使合成图像不可靠，无法用于诊断目的。
1.1 Classical approaches
1.2 Generative models
1.3 Medical image translation
1.4 Contributions
MedGAN的主要目的不是诊断，而是进一步增强需要全局一致图像属性的技术后处理任务。

MedGAN通过结合对抗性框架和一种新 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409191616851.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks">【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-19T09:19:12.000Z" title="发表于 2024-09-19 17:19:12">2024-09-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/DCGAN/">DCGAN</a></span></div><div class="content">Abstract
背景：希望能缩小CNN在监督学习和无监督学习之间成功应用的差距。
贡献：引入了一类称为深度卷积生成对抗网络（DCGAN）的CNN。
结果：DCGAN 在生成器和判别器中都能从对象到场景学习表示层次结构。
1. Introduction
贡献：
提出DCGAN
用于图像分类任务，展示其性能
对滤波器进行了可视化，证明特定滤波器已经学会了绘制特定对象
生成器具有向量算术特性，允许轻松操作生成样本的许多语义特征

2. Related Work
2.1 Representation Learning From Unlabeled Data——基于未标记数据的表示学习

聚类
自动编码器

2.2 Generating Natural Images——生成自然图像
生成图像模型分为两类：参数和非参数。
2.3 Visualizing The Internals Of CNNs——CNN内部可视化
使用输入上的梯度下降，可以检查激活某些滤波器子集的理想图像。
3. Approach And Model Architecture

DCGAN的架构：

用带步长的卷积（判别器）和 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/gan-gan/" title="【论文阅读】Generative Adversarial Nets"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409182316153.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Generative Adversarial Nets"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-gan/" title="【论文阅读】Generative Adversarial Nets">【论文阅读】Generative Adversarial Nets</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-18T15:14:36.000Z" title="发表于 2024-09-18 23:14:36">2024-09-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span></div><div class="content">Abstract
本文贡献：提出GAN：生成模型 G ，生成模型用来捕获数据的分布；辨别模型 D ，辨别模型用来判断样本是来自于训练数据还是生成模型生成的。
在任意函数空间里，存在唯一解，G 能找出训练数据的真实分布，而 D 的预测概率为 $\frac{1}{2}$ 。
结果：该框架是可行的。
1. Introduction
生成模型问题：在最大似然估计时会遇到很多棘手的近似概率计算。对抗网络：生成模型与判别模型相比较，学习确定样本是来自模型分布还是来自数据分布。生成模型可以通过多层感知机来实现，输入为一些随机噪声，可以通过反向传播来训练。
2. Related work

Boltzmann machine（玻尔兹曼机）：似然函数难以处理，需要多次近似
Generative stochastic networks（生成式随机网络）：用精确的反向传播进行训练
Markov chains（马尔可夫链）：本文通过消除生成随机网络中的马尔可夫链，扩展了生成模型的概念
variational autoencoders（VAE，变分自编码器）：将可微生成网络与执行近似推理的识别模型配对
Nois ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-hris/" title="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409121843542.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-hris/" title="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs">【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-12T13:36:37.000Z" title="发表于 2024-09-12 21:36:37">2024-09-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span></div><div class="content">Abstract
方法：一种新的对抗性损失函数以及新颖的多尺度生成器和判别器架构，生成了2048×1024分辨率的图像。加入了两个用于交互式视觉操作的新功能。

整合了对象实例分割信息，使得能够进行对象的操作，例如移除/添加对象以及更改对象类别。
提出了一种方法，在相同输入下生成多样化的结果，允许用户交互式地编辑对象外观。

1. Introduction
讨论了一种新的方法，产生高分辨率图像的语义标签映射。首先仅通过对抗性训练获得结果，而不依赖任何手工制作的损失或预先训练的网络进行感知损失。然后，如果预训练网络可用，则添加来自预训练网络的感知损失可以在某些情况下略微改善结果。利用实例级对象分割信息，将同一类别内的不同对象实例进行分割。提出了一种方法来生成不同的结果，给定相同的输入标签映射，允许用户交互编辑相同对象的外观。
2. Related Work
Generative adversarial networks（生成对抗网络）：旨在通过强制生成的样本与自然图像不可区分来模拟自然图像分布。
Image-to-image translation（图像到图像的转换）：在给定输入输出图像 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/gan-uiti/" title="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409112008921.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-uiti/" title="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks">【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-11T14:30:23.000Z" title="发表于 2024-09-11 22:30:23">2024-09-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CycleGAN/">CycleGAN</a></span></div><div class="content">Abstract
背景：成对训练数据缺乏。
方法：学习一个映射 $G:X→Y$，使得来自G(X)的图像分布与使用对抗性损失的分布Y是不可区分的。由于该映射是高度欠约束的，将其与逆映射 $F:Y→X$ 耦合，并引入循环一致性损失提出 $F(G(X))≈X$。
1. Introduction
提出系统：在没有任何成对的训练例子，捕捉一个图像采集的特殊特征，找出如何将这些特征转化为其他图像采集。
尽管缺乏成对示例形式的监督，但可以利用集合级别的监督：给定领域 X 中的一组图像和领域 Y 中的另一组图像。训练一个映射 $G:X→Y$，使得 $x∈X$ 的输出 $\hat{y} = G(x)$ ，对于对抗器来说 $\hat{y}$ 与领域 Y 中的图像 $y$ 无法区分。理论上，这一目标可以在 $\hat{y}$​ 上引导出一个输出分布，使其与经验分布 $p_Y(y)$ 相匹配（通常需要 G 是随机的）。因此，最优的 G 将领域 X 转换为分布与领域 Y 完全一致的领域 $\hat{Y}$。然而，这种转换并不能保证输入和输出 x 与 y 在个体层面上有有意义的配对——存在无限多个映射 G，它们可 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/gan-bmsg/" title="【论文阅读】Bone metastasis scintigram generation using generative adversarial learning with multi‐receptive field learning and two‐stage training"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409092216234.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Bone metastasis scintigram generation using generative adversarial learning with multi‐receptive field learning and two‐stage training"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-bmsg/" title="【论文阅读】Bone metastasis scintigram generation using generative adversarial learning with multi‐receptive field learning and two‐stage training">【论文阅读】Bone metastasis scintigram generation using generative adversarial learning with multi‐receptive field learning and two‐stage training</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-10T09:38:26.000Z" title="发表于 2024-09-10 17:38:26">2024-09-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/BoneMetastasis/">BoneMetastasis</a></span></div><div class="content">Abstract
背景：需要一种能扩大SPECT骨显像数据集的数据生成方法。
方法：一种基于深度学习的SPECT骨显像生成模型。采用生成对抗学习结构，提出骨转移显像生成模型（bone metastasis scintigram generation model，BMS-Gen）。BMS-Gen采用多输入条件和多感受野学习来确保生成样本的真实性。BMS-Gen采用生成对抗学习来保持生成样本的多样性。BMS-Gen采用两阶段训练策略来提高生成样本的质量。
结果：在 SPECT 骨转移显像图的临床数据上进行的实验评估显示了BMS-Gen的性能。在FID（Fréchet初始距离）、MSE（均方误差）和PSNR（峰值信噪比）指标上获得了最好的总分。在图像分类和分割任务中，BMS-Gen生成的样本的引入使F-1得分最大（最小）增加了3.01%（0.15%），DSC得分最大（最小）增加了6.83%（2.21%）。
1. Introduction

$^{99m}\text{Tc-MDP}$ (technetium-99 methylene phosphonic acid)——锝-99亚甲基二膦酸盐
 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/gan-itit/" title="【论文阅读】Image-to-Image Translation with Conditional Adversarial Networks"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409072345976.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Image-to-Image Translation with Conditional Adversarial Networks"></a></div><div class="recent-post-info"><a class="article-title" href="/gan-itit/" title="【论文阅读】Image-to-Image Translation with Conditional Adversarial Networks">【论文阅读】Image-to-Image Translation with Conditional Adversarial Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-09T08:51:30.000Z" title="发表于 2024-09-09 16:51:30">2024-09-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span></div><div class="content">Abstract
本文贡献：
研究条件对抗网络作为一个通用的解决图像到图像的翻译问题的方案。
不仅学习从输入图像到输出图像的映射，而且学习一个损失函数来训练这种映射。结果：
使得对传统上需要不同的损失公式的问题采用相同的普遍方法成为可能。

1. Introduction

将自动的图像到图像翻译定义为，在给定足够训练数据的情况下，将场景的一种可能表示转换为另一种可能表示的问题。



predict pixels from pixels
CNN 学习最小化损失函数，即对结果质量进行评分的目标——尽管学习过程是自动的，但仍需要大量手动工作来设计有效的损失。迫使 CNN 做我们真正想要的损失函数——例如，输出清晰、逼真的图像。
GANs学习一个损失，试图分类输出图像是真是假，同时训练生成模型，以尽量减少这种损失。由于GANs学习的是与数据相适应的损失，因此它们可以应用于传统上需要不同类型的损失函数的大量任务。
cGANs学习条件生成模型。这使得cGAN适合于图像到图像的转换任务，其中对输入图像进行条件处理并生成相应的输出图像。

2. Related work
Structured lo ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/image-synthesis-review-02/" title="【论文阅读】深度学习图像数据增广方法研究综述"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409061017167.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】深度学习图像数据增广方法研究综述"></a></div><div class="recent-post-info"><a class="article-title" href="/image-synthesis-review-02/" title="【论文阅读】深度学习图像数据增广方法研究综述">【论文阅读】深度学习图像数据增广方法研究综述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-06T16:03:57.000Z" title="发表于 2024-09-07 00:03:57">2024-09-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span></div><div class="content">摘要
背景：充足的训练数据不仅可以缓解模型在训练时的过拟合问题，而且可以进一步扩大参数搜索空间，帮助模型进一步朝着全局最优解优化。然而，在许多领域或任务中，获取到充足训练样本的难度和代价非常高。因此，数据增广成为一种常用的增加训练样本的手段。
本文贡献：按照方法本质原理的不同，将其分为单数据变形、多数据混合、学习数据分布和学习增广策略等 4 类方法。单数据变形方法主要可以分为几何变换、色域变换、清晰度变换、噪声注入和局部擦除等 5 种；多数据混合可按照图像维度的混合和特征空间下的混合进行划分；学习数据分布的方法主要基于生成对抗网络和图像风格迁移的应用进行划分；学习增广策略的典型方法可以按照基于元学习和基于强化学习进行分类
前景：根据数据和任务基于强化学习探索最优的组合策略，基于元学习自适应地学习最优数据变形和混合方式，基于生成对抗网络进一步拟合真实数据分布以采样高质量的未知数据，基于风格迁移探索多模态数据互相转换的应用
0. 引言
在许多研究领域，受限于数据获取难度大、标注成本高等原因，往往难以获得充足的训练数据，这样训练得到的深度学习模型往往存在过拟合的问题，进而导致模型泛化能力差、 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/image-synthesis-review-01/" title="【论文阅读】医学图像数据集扩充方法研究进展"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409051723906.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】医学图像数据集扩充方法研究进展"></a></div><div class="recent-post-info"><a class="article-title" href="/image-synthesis-review-01/" title="【论文阅读】医学图像数据集扩充方法研究进展">【论文阅读】医学图像数据集扩充方法研究进展</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-05T14:00:07.000Z" title="发表于 2024-09-05 22:00:07">2024-09-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/GAN/">GAN</a></span></div><div class="content">摘要
背景：
计算机辅助诊断（CAD）
训练样本受成像成本、标记成本和涉及患者隐私等因素的影响，导致训练图像多样性不足且难以获取。本文贡献：对医学图像数据集扩充方法的研究进展进行综述。


对比分析基于几何变换和基于生成对抗网络的扩充方法；
介绍基于生成对抗网络扩充方法的改进及其适用场景；
讨论医学图像数据集扩充领域的一些亟待解决的问题并对其未来发展趋势进行展望。

0. 引言
医学图像成像模态：

磁共振成像（magnetic resonance imaging，MRI）
计算机断层扫描成像（computed tomography，CT）
正电子发射断层扫描成像（positron emission computed tomography，PET）

诊断难点：医学图像信息量庞大以及部分疾病的病变部位细小
医学图像数据集扩充方法：基于几何变换和基于生成对抗网络（generative adversarial network，GAN）的扩充方法
1. 基于几何变换的医学图像数据集扩充方法
两种操作方式：

针对图像中像素点的灰度值进行操作，通过一系列变换函数的映射，改变像素点位置信息，使其 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/spect-adob/" title="【论文阅读】Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks"><img class="post-bg" src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409031701127.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks"></a></div><div class="recent-post-info"><a class="article-title" href="/spect-adob/" title="【论文阅读】Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks">【论文阅读】Automated diagnosis of bone metastasis based on multi-view bone scans using attention-augmented deep neural networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-02T08:36:00.000Z" title="发表于 2024-09-02 16:36:00">2024-09-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><i class="fas fa-angle-right article-meta-link"></i><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%88%86%E5%89%B2/">分割</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/SPECT/">SPECT</a></span></div><div class="content">Abstract
背景：手动分析骨显像图像需要丰富的经验，已有骨显像图像的自动或半自动诊断方法步骤复杂且在小数据集上验证不足，准确性和可靠性较低。
本文贡献：描述了一个深度卷积神经网络的方法，该方法有两个主要创新点：首先，通过联合分析前后视图进行诊断，从而获得较高的准确性。其次，提出了一种空间注意特征聚集算子来增强空间位置信息。
结果：高分类准确率证明了所提出的体系结构对骨显像图像诊断的有效性，可作为临床决策支持工具应用。
1. Introduction
背景：全身骨扫描（WBS）在骨转移的鉴别诊断中与MRI具有相似的性能，但其成本远低于MRI

磁共振成像（magnetic resonance imaging，MRI）
计算机断层扫描（computed tomography，CT）
全身骨扫描（whole-body bone scan，WBS）

WBS图像中的异常称为热点（hot spot），通常表现为比周围环境更高的信号强度。但没有骨转移的患者也可以在WBS图像上显示热点。
骨转移的自动诊断方法的发展面临以下几个障碍：

各种非肿瘤性疾病在影像学表现上也表现出异常，导致高灵敏度和 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/spy_family_avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">BulingQAQ</div><div class="author-info__description">不知归路，宁愿一世无悔追逐</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/YanQinglei"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/YanQinglei" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://blog.csdn.net/OctYZ" target="_blank" title="CSDN"><i class="fa fa-book-open"></i></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1819615836&amp;website=www.oicqzone.com" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="mailto:1819615836@qq.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">请多多指教</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409202307724.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】MedGAN:Medical image translation using GANs"/></a><div class="content"><a class="title" href="/gan-mmit/" title="【论文阅读】MedGAN:Medical image translation using GANs">【论文阅读】MedGAN:Medical image translation using GANs</a><time datetime="2024-09-21T14:04:30.000Z" title="发表于 2024-09-21 22:04:30">2024-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409191616851.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"/></a><div class="content"><a class="title" href="/gan-urlw/" title="【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks">【论文阅读】Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a><time datetime="2024-09-19T09:19:12.000Z" title="发表于 2024-09-19 17:19:12">2024-09-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-gan/" title="【论文阅读】Generative Adversarial Nets"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409182316153.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Generative Adversarial Nets"/></a><div class="content"><a class="title" href="/gan-gan/" title="【论文阅读】Generative Adversarial Nets">【论文阅读】Generative Adversarial Nets</a><time datetime="2024-09-18T15:14:36.000Z" title="发表于 2024-09-18 23:14:36">2024-09-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-hris/" title="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409121843542.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"/></a><div class="content"><a class="title" href="/gan-hris/" title="【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs">【论文阅读】High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</a><time datetime="2024-09-12T13:36:37.000Z" title="发表于 2024-09-12 21:36:37">2024-09-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/gan-uiti/" title="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"><img src="https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409112008921.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"/></a><div class="content"><a class="title" href="/gan-uiti/" title="【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks">【论文阅读】Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks</a><time datetime="2024-09-11T14:30:23.000Z" title="发表于 2024-09-11 22:30:23">2024-09-11</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="card-category-list-name">论文阅读</span><span class="card-category-list-count">10</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%88%86%E5%89%B2/"><span class="card-category-list-name">分割</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"><span class="card-category-list-name">图像生成</span><span class="card-category-list-count">9</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/GAN/" style="font-size: 1.5em; color: #99a9bf">GAN</a> <a href="/tags/BoneMetastasis/" style="font-size: 1.1em; color: #999">BoneMetastasis</a> <a href="/tags/MedGAN/" style="font-size: 1.1em; color: #999">MedGAN</a> <a href="/tags/SPECT/" style="font-size: 1.1em; color: #999">SPECT</a> <a href="/tags/DCGAN/" style="font-size: 1.1em; color: #999">DCGAN</a> <a href="/tags/CycleGAN/" style="font-size: 1.1em; color: #999">CycleGAN</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">11</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">28.8k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-09-21T14:27:43.893Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://raw.githubusercontent.com/YanQinglei/blog-img/main/img202409021053834.png')"><div id="footer-wrap"><div class="copyright">&copy;2024 By BulingQAQ</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生","虽千万人吾往矣","长风破浪会有时，直挂云帆济沧海","三军可夺帅也，匹夫不可夺志也","俱往矣，数风流人物，还看今朝","问汝平生功业，黄州惠州儋州"])
  } else {
    document.getElementById("subtitle").textContent = "竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生"
  }
}
typedJSFn.run(subtitleType)</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>